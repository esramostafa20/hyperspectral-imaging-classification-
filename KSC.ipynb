{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpalJcNy9kkB"
      },
      "source": [
        "import keras,os\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Convolution2D, Conv2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation,AveragePooling2D\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWcGbMmd136Y"
      },
      "source": [
        "#Alexnet\n",
        "#Instantiate an empty model\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(14,14,1), kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "# model.add(padding=’valid’)\n",
        "# Max Pooling\n",
        "# model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "# model.add(Activation(‘relu’))\n",
        "# Max Pooling\n",
        "# model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "# model.add(Activation(‘relu’))\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "# model.add(Activation(‘relu’))\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
        "# model.add(Activation(‘relu’))\n",
        "# Max Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n",
        "\n",
        "# Passing it to a Fully Connected layer\n",
        "model.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,), activation='relu'))\n",
        "# model.add(Activation(‘relu’))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# 2nd Fully Connected Layer\n",
        "model.add(Dense(4096,activation='relu',kernel_initializer='he_normal'))\n",
        "# model.add(Activation(‘relu’))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# 3rd Fully Connected Layer\n",
        "model.add(Dense(1000,activation='relu',kernel_initializer='he_normal'))\n",
        "# model.add(Activation(‘relu’))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(14,activation='softmax',kernel_initializer='he_normal'))\n",
        "# model.add(Activation(‘softmax’))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2qON8Ux136Z",
        "outputId": "f1f9dca9-36c6-4253-a991-92b571fa15d2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 12, 12, 96)        960       \n",
            "_________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2 (None, 14, 14, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 12, 12, 256)       221440    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPaddin (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 384)       885120    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              51384320  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 14)                14014     \n",
            "=================================================================\n",
            "Total params: 75,596,646\n",
            "Trainable params: 75,596,646\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwuWu9ZA136a"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "U4Zs-BZx136a",
        "outputId": "8e283a4c-a989-49dc-8437-e484fceb5c67"
      },
      "source": [
        " from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"KSCAlexNet.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "model.fit(x_train , y_train, batch_size=512,validation_split=0.3, epochs=50,shuffle=True,callbacks=[checkpoint,early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f5c77b746801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KSCAlexNet.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mearly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnuuIGQ0136b"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1,1),input_shape=(14,14, 1)))\n",
        "model.add(Convolution2D(64, (3, 3), strides=(1,1), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(64, (3, 3), strides=(1,1), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(1,1)))\n",
        " \n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), strides=(1,1), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), strides=(1,1), activation='relu'))\n",
        "model.add(MaxPooling2D((1,1), strides=(1,1)))\n",
        "\n",
        "model.add(AveragePooling2D(pool_size=8))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(14,activation='softmax',kernel_initializer='he_normal'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukXNR_V3136b",
        "outputId": "152ede33-82d6-4fba-ffe3-ef57f952a738"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 12, 12, 96)        960       \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 14, 14, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 12, 256)       221440    \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 12, 12, 384)       885120    \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 10, 10, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              51384320  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 14)                14014     \n",
            "=================================================================\n",
            "Total params: 75,596,646\n",
            "Trainable params: 75,596,646\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz6zyfXp9kkO"
      },
      "source": [
        "sgd = keras.optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy'\n",
        "                  , optimizer = sgd\n",
        "                  , metrics=['accuracy']\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnmcd4Qf9kkU"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwDtWFoR136c"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"KSCSimple.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "model.fit(x_train, y_train, batch_size=512,validation_split=0.3, epochs=50,shuffle=True,callbacks=[checkpoint,early])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S5f0D_lb9kkY",
        "scrolled": true,
        "outputId": "da6535ab-c6b5-4db5-e0f7-d539578d10e2"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"KSC.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "model.fit(x_train, y_train, batch_size=512,validation_split=0.3, epochs=50,shuffle=True,callbacks=[checkpoint,early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 210000 samples, validate on 90001 samples\n",
            "Epoch 1/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.1976 - accuracy: 0.9831\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.98391, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 228s 1ms/sample - loss: 0.1976 - accuracy: 0.9831 - val_loss: 0.1719 - val_accuracy: 0.9839\n",
            "Epoch 2/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.1644 - accuracy: 0.9831\n",
            "Epoch 00002: val_accuracy did not improve from 0.98391\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.1644 - accuracy: 0.9831 - val_loss: 0.1503 - val_accuracy: 0.9839\n",
            "Epoch 3/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9831\n",
            "Epoch 00003: val_accuracy did not improve from 0.98391\n",
            "210000/210000 [==============================] - 225s 1ms/sample - loss: 0.1409 - accuracy: 0.9831 - val_loss: 0.1243 - val_accuracy: 0.9839\n",
            "Epoch 4/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9831\n",
            "Epoch 00004: val_accuracy did not improve from 0.98391\n",
            "210000/210000 [==============================] - 225s 1ms/sample - loss: 0.1241 - accuracy: 0.9831 - val_loss: 0.1208 - val_accuracy: 0.9839\n",
            "Epoch 5/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9831\n",
            "Epoch 00005: val_accuracy improved from 0.98391 to 0.98392, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.1128 - accuracy: 0.9831 - val_loss: 0.1039 - val_accuracy: 0.9839\n",
            "Epoch 6/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 0.9831\n",
            "Epoch 00006: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 226s 1ms/sample - loss: 0.1045 - accuracy: 0.9831 - val_loss: 0.1201 - val_accuracy: 0.9839\n",
            "Epoch 7/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9831\n",
            "Epoch 00007: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 220s 1ms/sample - loss: 0.0978 - accuracy: 0.9831 - val_loss: 0.0895 - val_accuracy: 0.9839\n",
            "Epoch 8/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9831\n",
            "Epoch 00008: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 220s 1ms/sample - loss: 0.0941 - accuracy: 0.9831 - val_loss: 0.0957 - val_accuracy: 0.9839\n",
            "Epoch 9/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9831\n",
            "Epoch 00009: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0920 - accuracy: 0.9831 - val_loss: 0.0989 - val_accuracy: 0.9839\n",
            "Epoch 10/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0894 - accuracy: 0.9831\n",
            "Epoch 00010: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 225s 1ms/sample - loss: 0.0894 - accuracy: 0.9831 - val_loss: 0.0885 - val_accuracy: 0.9838\n",
            "Epoch 11/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9831\n",
            "Epoch 00011: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 225s 1ms/sample - loss: 0.0865 - accuracy: 0.9831 - val_loss: 0.0833 - val_accuracy: 0.9839\n",
            "Epoch 12/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.9831\n",
            "Epoch 00012: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0836 - accuracy: 0.9831 - val_loss: 0.0831 - val_accuracy: 0.9837\n",
            "Epoch 13/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9831\n",
            "Epoch 00013: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0835 - accuracy: 0.9831 - val_loss: 0.0809 - val_accuracy: 0.9839\n",
            "Epoch 14/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 0.9831\n",
            "Epoch 00014: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0822 - accuracy: 0.9831 - val_loss: 0.0783 - val_accuracy: 0.9838\n",
            "Epoch 15/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9830\n",
            "Epoch 00015: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 230s 1ms/sample - loss: 0.0810 - accuracy: 0.9830 - val_loss: 0.0804 - val_accuracy: 0.9839\n",
            "Epoch 16/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9831\n",
            "Epoch 00016: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0800 - accuracy: 0.9831 - val_loss: 0.0878 - val_accuracy: 0.9839\n",
            "Epoch 17/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9831\n",
            "Epoch 00017: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 229s 1ms/sample - loss: 0.0794 - accuracy: 0.9831 - val_loss: 0.0801 - val_accuracy: 0.9839\n",
            "Epoch 18/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9831\n",
            "Epoch 00018: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 229s 1ms/sample - loss: 0.0789 - accuracy: 0.9831 - val_loss: 0.1110 - val_accuracy: 0.9839\n",
            "Epoch 19/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9831\n",
            "Epoch 00019: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 232s 1ms/sample - loss: 0.0803 - accuracy: 0.9831 - val_loss: 0.0801 - val_accuracy: 0.9839\n",
            "Epoch 20/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 0.9831\n",
            "Epoch 00020: val_accuracy did not improve from 0.98392\n",
            "210000/210000 [==============================] - 240s 1ms/sample - loss: 0.0772 - accuracy: 0.9831 - val_loss: 0.0895 - val_accuracy: 0.9839\n",
            "Epoch 21/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 0.9830\n",
            "Epoch 00021: val_accuracy improved from 0.98392 to 0.98394, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 238s 1ms/sample - loss: 0.0785 - accuracy: 0.9830 - val_loss: 0.0956 - val_accuracy: 0.9839\n",
            "Epoch 22/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9831\n",
            "Epoch 00022: val_accuracy improved from 0.98394 to 0.98396, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 227s 1ms/sample - loss: 0.0770 - accuracy: 0.9831 - val_loss: 0.0865 - val_accuracy: 0.9840\n",
            "Epoch 23/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9831\n",
            "Epoch 00023: val_accuracy did not improve from 0.98396\n",
            "210000/210000 [==============================] - 237s 1ms/sample - loss: 0.0757 - accuracy: 0.9831 - val_loss: 0.0951 - val_accuracy: 0.9839\n",
            "Epoch 24/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0756 - accuracy: 0.9832\n",
            "Epoch 00024: val_accuracy improved from 0.98396 to 0.98403, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 250s 1ms/sample - loss: 0.0756 - accuracy: 0.9832 - val_loss: 0.0824 - val_accuracy: 0.9840\n",
            "Epoch 25/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 0.9832\n",
            "Epoch 00025: val_accuracy did not improve from 0.98403\n",
            "210000/210000 [==============================] - 231s 1ms/sample - loss: 0.0751 - accuracy: 0.9832 - val_loss: 0.0791 - val_accuracy: 0.9839\n",
            "Epoch 26/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 0.9832\n",
            "Epoch 00026: val_accuracy did not improve from 0.98403\n",
            "210000/210000 [==============================] - 225s 1ms/sample - loss: 0.0737 - accuracy: 0.9832 - val_loss: 0.0743 - val_accuracy: 0.9839\n",
            "Epoch 27/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.9831\n",
            "Epoch 00027: val_accuracy did not improve from 0.98403\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0734 - accuracy: 0.9831 - val_loss: 0.1072 - val_accuracy: 0.9839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9832\n",
            "Epoch 00028: val_accuracy improved from 0.98403 to 0.98406, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 962s 5ms/sample - loss: 0.0731 - accuracy: 0.9832 - val_loss: 0.0742 - val_accuracy: 0.9841\n",
            "Epoch 29/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9832\n",
            "Epoch 00029: val_accuracy did not improve from 0.98406\n",
            "210000/210000 [==============================] - 219s 1ms/sample - loss: 0.0726 - accuracy: 0.9832 - val_loss: 0.0782 - val_accuracy: 0.9840\n",
            "Epoch 30/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0733 - accuracy: 0.9832\n",
            "Epoch 00030: val_accuracy did not improve from 0.98406\n",
            "210000/210000 [==============================] - 222s 1ms/sample - loss: 0.0733 - accuracy: 0.9832 - val_loss: 0.0714 - val_accuracy: 0.9840\n",
            "Epoch 31/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9832\n",
            "Epoch 00031: val_accuracy did not improve from 0.98406\n",
            "210000/210000 [==============================] - 222s 1ms/sample - loss: 0.0721 - accuracy: 0.9832 - val_loss: 0.0727 - val_accuracy: 0.9840\n",
            "Epoch 32/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 0.9831\n",
            "Epoch 00032: val_accuracy did not improve from 0.98406\n",
            "210000/210000 [==============================] - 223s 1ms/sample - loss: 0.0715 - accuracy: 0.9831 - val_loss: 0.0695 - val_accuracy: 0.9840\n",
            "Epoch 33/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9833\n",
            "Epoch 00033: val_accuracy improved from 0.98406 to 0.98409, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 280s 1ms/sample - loss: 0.0716 - accuracy: 0.9833 - val_loss: 0.0801 - val_accuracy: 0.9841\n",
            "Epoch 34/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9832\n",
            "Epoch 00034: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0702 - accuracy: 0.9832 - val_loss: 0.0700 - val_accuracy: 0.9837\n",
            "Epoch 35/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9832\n",
            "Epoch 00035: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0701 - accuracy: 0.9832 - val_loss: 0.0751 - val_accuracy: 0.9836\n",
            "Epoch 36/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9831\n",
            "Epoch 00036: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0717 - accuracy: 0.9831 - val_loss: 0.0752 - val_accuracy: 0.9839\n",
            "Epoch 37/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9832\n",
            "Epoch 00037: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0716 - accuracy: 0.9832 - val_loss: 0.1078 - val_accuracy: 0.9841\n",
            "Epoch 38/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9833\n",
            "Epoch 00038: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0692 - accuracy: 0.9833 - val_loss: 0.0766 - val_accuracy: 0.9840\n",
            "Epoch 39/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9832\n",
            "Epoch 00039: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 225s 1ms/sample - loss: 0.0699 - accuracy: 0.9832 - val_loss: 0.0751 - val_accuracy: 0.9840\n",
            "Epoch 40/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9833\n",
            "Epoch 00040: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 228s 1ms/sample - loss: 0.0684 - accuracy: 0.9833 - val_loss: 0.0795 - val_accuracy: 0.9839\n",
            "Epoch 41/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9832\n",
            "Epoch 00041: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 225s 1ms/sample - loss: 0.0686 - accuracy: 0.9832 - val_loss: 0.1067 - val_accuracy: 0.9840\n",
            "Epoch 42/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9832\n",
            "Epoch 00042: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0719 - accuracy: 0.9832 - val_loss: 0.0755 - val_accuracy: 0.9841\n",
            "Epoch 43/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9832\n",
            "Epoch 00043: val_accuracy did not improve from 0.98409\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0711 - accuracy: 0.9832 - val_loss: 0.0781 - val_accuracy: 0.9835\n",
            "Epoch 44/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9831\n",
            "Epoch 00044: val_accuracy improved from 0.98409 to 0.98410, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0685 - accuracy: 0.9831 - val_loss: 0.0690 - val_accuracy: 0.9841\n",
            "Epoch 45/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9834\n",
            "Epoch 00045: val_accuracy did not improve from 0.98410\n",
            "210000/210000 [==============================] - 224s 1ms/sample - loss: 0.0677 - accuracy: 0.9834 - val_loss: 0.0807 - val_accuracy: 0.9836\n",
            "Epoch 46/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9833\n",
            "Epoch 00046: val_accuracy improved from 0.98410 to 0.98419, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 223s 1ms/sample - loss: 0.0678 - accuracy: 0.9833 - val_loss: 0.1037 - val_accuracy: 0.9842\n",
            "Epoch 47/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 0.9834\n",
            "Epoch 00047: val_accuracy did not improve from 0.98419\n",
            "210000/210000 [==============================] - 222s 1ms/sample - loss: 0.0672 - accuracy: 0.9834 - val_loss: 0.0694 - val_accuracy: 0.9837\n",
            "Epoch 48/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 0.9832\n",
            "Epoch 00048: val_accuracy did not improve from 0.98419\n",
            "210000/210000 [==============================] - 220s 1ms/sample - loss: 0.0672 - accuracy: 0.9832 - val_loss: 0.0843 - val_accuracy: 0.9840\n",
            "Epoch 49/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9835\n",
            "Epoch 00049: val_accuracy improved from 0.98419 to 0.98428, saving model to KSC.h5\n",
            "210000/210000 [==============================] - 221s 1ms/sample - loss: 0.0662 - accuracy: 0.9835 - val_loss: 0.0695 - val_accuracy: 0.9843\n",
            "Epoch 50/50\n",
            "209920/210000 [============================>.] - ETA: 0s - loss: 0.0687 - accuracy: 0.9832\n",
            "Epoch 00050: val_accuracy did not improve from 0.98428\n",
            "210000/210000 [==============================] - 222s 1ms/sample - loss: 0.0686 - accuracy: 0.9832 - val_loss: 0.0673 - val_accuracy: 0.9840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbaa4283d50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P41LdRomkrm-",
        "outputId": "52ab5a3b-0786-4441-ff2a-09534c8f2576"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o18yBRPo-ADe"
      },
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Jp2LKp136d"
      },
      "source": [
        "\n",
        "x = loadmat('/content/drive/MyDrive/Downloads/KSC.mat')\n",
        "KSC = x['KSC']\n",
        "x = loadmat('/content/drive/MyDrive/Downloads/KSC_gt.mat')\n",
        "KSC_gt = x['KSC_gt']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HaEaf_q136d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba14014-672e-4225-d1c5-c41850cab405"
      },
      "source": [
        "print(len(KSC[1]))\n",
        "print(len(KSC))\n",
        "print(len(KSC[1][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "614\n",
            "512\n",
            "176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jm-RTBT136e",
        "outputId": "52eec56d-e29e-4e05-9b8f-0b8525c4d17e"
      },
      "source": [
        "print(KSC_gt[1][0])\n",
        "print(len(KSC_gt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0thjsoM136e"
      },
      "source": [
        "training_data=[]\n",
        "i=0\n",
        "while(i<len(KSC_gt)):\n",
        "    j=0\n",
        "    while(j<len(KSC_gt[i])):\n",
        "        x=KSC[i][j]\n",
        "        x=np.array(x)\n",
        "        zero=np.array([0])\n",
        "        z=0\n",
        "        while(z<20):\n",
        "            x=np.append(x,zero)\n",
        "            z=z+1\n",
        "        x= np.array(x).reshape((14,14, 1 ))\n",
        "        training_data.append([x,KSC_gt[i][j]])\n",
        "        j=j+1\n",
        "    i=i+1\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbDuJvqO136e"
      },
      "source": [
        "import random\n",
        "random.shuffle(training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR2Lftan136e"
      },
      "source": [
        "x_train =[]\n",
        "y_train = []\n",
        "i=0\n",
        "for features,label in training_data:\n",
        "    if(i>300000):\n",
        "        break\n",
        "    x_train.append(features)\n",
        "    y_train.append(label)\n",
        "    i=i+1\n",
        "x_train=np.array(x_train)\n",
        "y_train=np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz93OMRe136f",
        "outputId": "d06427a4-8ddd-428e-f64e-cb66c03b3273"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300001, 14, 14, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDOCnvN2136f",
        "outputId": "6665bcac-4dcd-4d03-f0e5-586e37dae53f"
      },
      "source": [
        "print(len(training_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "314368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWmV7WID136f"
      },
      "source": [
        "x_val=x_train[300000:314368]\n",
        "y_val=y_train[300000:314368]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlLrdOgo136f",
        "outputId": "4c1a15ef-c6da-4fa7-842a-91268818f853"
      },
      "source": [
        "x_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 14, 14, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NvJoIxu136g"
      },
      "source": [
        "# run this only once afte creating y_train\n",
        "y_train = keras.utils.to_categorical(y_train, 14)\n",
        "y_val=keras.utils.to_categorical(y_val, 14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5U90Dc-136g",
        "outputId": "1c741cac-430d-4975-8de6-72fd6d13e45f"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYv1Wa0L136h"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "model= models.load_model(\"KSC.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeQOyh3p136h"
      },
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy1Du2d0136h"
      },
      "source": [
        "x = loadmat('Indian Pines/Indian_pines.mat')\n",
        "Indian_pines = x['Indian_pines']\n",
        "x = loadmat('Indian Pines/Indian_pines_corrected.mat')\n",
        "Indian_pines_corrected = x['Indian_pines_corrected']\n",
        "x = loadmat('Indian Pines/Indian_pines_gt.mat')\n",
        "Indian_pines_gt = x['Indian_pines_gt']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOI7K0Te136h"
      },
      "source": [
        "training_data=[]\n",
        "i=0\n",
        "while(i<len(Indian_pines_gt)):\n",
        "    j=0\n",
        "    while(j<len(Indian_pines_gt[i])):\n",
        "        x=Indian_pines[i][j]\n",
        "        x=np.array(x)\n",
        "        zero=np.array([0])\n",
        "        z=0\n",
        "        while(z<32):\n",
        "            x=np.append(x,zero)\n",
        "            z=z+1\n",
        "        x= np.array(x).reshape((16,16, 1 ))\n",
        "        training_data.append([x,Indian_pines_gt[i][j]])\n",
        "        j=j+1\n",
        "    i=i+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tmF2LDW136i"
      },
      "source": [
        "import random\n",
        "random.shuffle(training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnCpdwmW136i"
      },
      "source": [
        "a = len(training_data)/8\n",
        "print(a)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QF9JfYH136i"
      },
      "source": [
        "x_train =[]\n",
        "y_train = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    x_train.append(features)\n",
        "    y_train.append(label)\n",
        "x_train=np.array(x_train)\n",
        "y_train=np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUfD8bHY136i"
      },
      "source": [
        "import tensorflow as tf\n",
        "samplenum=75655\n",
        "test=x_train[samplenum]\n",
        "test= np.array(test).reshape((1,16,16, 1 ))\n",
        "test = tf.cast(test, tf.float32)\n",
        "prediction=model.predict([test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZGORMdY136i"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "calsses = ['Brocoli_green_weeds_1', 'Brocoli_green_weeds_2', 'Fallow', 'Fallow_rough_plow', 'Fallow_smooth', 'Stubble', 'Celery', 'Grapes_untrained', 'Soil_vinyard_develop', 'Corn_senesced_green_weeds', 'Lettuce_romaine_4wk', 'Lettuce_romaine_5wk', 'Lettuce_romaine_6wk', 'Lettuce_romaine_7wk', 'Vinyard_untrained', 'Vinyard_vertical_trellis', 'unknown']\n",
        "y_pos = np.arange(17)\n",
        "plt.bar(y_pos, prediction[0], alpha=1)\n",
        "result = np.where(prediction[0] == np.amax(prediction[0]))\n",
        "plt.ylabel('percentage')\n",
        "plt.title('class')\n",
        "plt.show()\n",
        "print('predicted class: ',calsses[result[0][0]])\n",
        "print ('Actual class: ',calsses[y_train[samplenum]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbo6AXb4136j"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "model= models.load_model(\"KSC.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLxS6j_A136j",
        "outputId": "3dbce04d-a843-4f15-f491-aca4a5fa3481"
      },
      "source": [
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.21867274497957165\n",
            "Test accuracy: 0.984549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in294PTL136j"
      },
      "source": [
        "x_val= np.array(x_val).reshape((-1,16,16, 1 ))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VT-OHkV136j"
      },
      "source": [
        "print(len(x_val))\n",
        "print(len(y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy9a13ce136j"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras \n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from skimage.feature import local_binary_pattern\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6DgHk7S136k"
      },
      "source": [
        "# Training parameters\n",
        "BATCH_SIZE = 32  # orig paper trained all networks with batch_size=128\n",
        "EPOCHS = 50 # 200\n",
        "USE_AUGMENTATION = True\n",
        "DEPTH = 3 * 6 + 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Ezlj3i136k"
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxOZXjl-136k"
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp3VHlUv136l"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=17):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = tensorflow.keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D()(x)\n",
        "    flatten = Flatten()(x)\n",
        "    outputs = Dense(14,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(flatten)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pu9Tm2Q136l"
      },
      "source": [
        "# Create the neural network\n",
        "model = resnet_v1(input_shape=(14,14,1), depth=DEPTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXlaloAi136l",
        "outputId": "13759f53-ee3f-4ff5-9b37-32839e72c109"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 14, 14, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 14, 14, 16)   160         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 14, 14, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 14, 14, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 14, 14, 16)   2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 14, 14, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 14, 14, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 14, 14, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 14, 14, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 14, 14, 16)   0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 14, 14, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 14, 14, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 14, 14, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 14, 14, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 14, 14, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 14, 14, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 14, 14, 16)   0           activation_2[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 14, 14, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 14, 14, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 14, 14, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 14, 14, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 14, 14, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 14, 14, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 14, 14, 16)   0           activation_4[0][0]               \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 14, 14, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 7, 7, 32)     4640        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 7, 7, 32)     128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 7, 7, 32)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 7, 7, 32)     9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 7, 7, 32)     544         activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 7, 7, 32)     128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 7, 7, 32)     0           conv2d_9[0][0]                   \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 7, 7, 32)     0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 7, 7, 32)     9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 7, 7, 32)     128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 7, 7, 32)     0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 7, 7, 32)     9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 7, 7, 32)     128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 7, 7, 32)     0           activation_8[0][0]               \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 7, 7, 32)     0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 7, 7, 32)     9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 7, 7, 32)     128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 7, 7, 32)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 7, 7, 32)     9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 7, 7, 32)     128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 7, 7, 32)     0           activation_10[0][0]              \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 7, 7, 32)     0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 4, 4, 64)     18496       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 4, 4, 64)     256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 4, 4, 64)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 4, 4, 64)     36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 64)     2112        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 4, 4, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 64)     0           conv2d_16[0][0]                  \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 4, 4, 64)     0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 64)     36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 4, 4, 64)     256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 4, 4, 64)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 4, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 4, 4, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 64)     0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 4, 4, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 64)     36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 4, 4, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 4, 4, 64)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 4, 4, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 64)     0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 4, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 2, 2, 64)     0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 256)          0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 14)           3598        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 277,102\n",
            "Trainable params: 275,726\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvJQm5mr136l"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}